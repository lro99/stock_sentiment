{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMKkSDn/L8t1WVA9K3C8ZxL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lro99/stock_sentiment/blob/main/SentimentTrading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install hf_xet"
      ],
      "metadata": {
        "id": "DLGNgjyJJDh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install newsapi-python"
      ],
      "metadata": {
        "id": "0O2DdcjdP_He"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install finnhub-python"
      ],
      "metadata": {
        "id": "9M9DktNoR4vf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# apikey = '62638dc7df5e4e958183e238948a0ebf'"
      ],
      "metadata": {
        "id": "uY_gUJoNduz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finhubkey = 'd06ltdpr01qg26s8pi6gd06ltdpr01qg26s8pi70'"
      ],
      "metadata": {
        "id": "CsZ9R7DnOi5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cimZOVzH2jnf"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# finBERT\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import pipeline\n",
        "# newsapi\n",
        "from newsapi import NewsApiClient\n",
        "import requests\n",
        "import finnhub\n",
        "# timeseries\n",
        "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, make_scorer\n",
        "# deep learning\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get list of news\n",
        "news = yf.Search(\"S&P 500\", news_count=10).news\n",
        "for i in news:\n",
        "  print(i['title'])"
      ],
      "metadata": {
        "id": "hwQuMorm28J-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# S&P500 yahoo\n",
        "\n",
        "ticker = yf.Ticker(\"SPY\")\n",
        "historical = ticker.history(period=\"10y\")\n",
        "historical"
      ],
      "metadata": {
        "id": "77qd_cAj3B4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "historical['Return'] = historical['Close'].pct_change() * 100\n",
        "historical['Lag1'] = historical['Return'].shift(1)\n",
        "historical['Lag2'] = historical['Return'].shift(2)\n",
        "historical['Lag3'] = historical['Return'].shift(3)\n",
        "historical['MA5'] = historical['Close'].rolling(5).mean()\n",
        "historical['MA20'] = historical['Close'].rolling(20).mean()\n",
        "historical['Volatility10'] = historical['Return'].rolling(10).std()\n",
        "historical['RoC10'] = historical['Close'].pct_change(periods=10)\n",
        "historical.dropna(inplace=True)\n",
        "\n",
        "\n",
        "X = historical[['Lag1', 'Lag2', 'Lag3', 'MA5', 'MA20', 'Volatility10', 'RoC10']]\n",
        "y = historical['Return']"
      ],
      "metadata": {
        "id": "sT45ff0sTMlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "8bSjR29BiYEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "historical.describe()"
      ],
      "metadata": {
        "id": "oy2tdCABTefg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline"
      ],
      "metadata": {
        "id": "Ww_T3LrIib98"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rolling Avg"
      ],
      "metadata": {
        "id": "iUfC7LoAW9Ph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "window = 5\n",
        "\n",
        "historical['RollingAvg_Pred'] = historical['Return'].shift(1).rolling(window).mean()\n"
      ],
      "metadata": {
        "id": "3_R0uNecUTjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_vals = historical['Return'].dropna()\n",
        "rolling_pred = historical['RollingAvg_Pred'].dropna()\n",
        "aligned = true_vals.loc[rolling_pred.index]\n",
        "\n",
        "mse = mean_squared_error(aligned, rolling_pred)\n",
        "mae = mean_absolute_error(aligned, rolling_pred)\n",
        "r2 = r2_score(aligned, rolling_pred)\n",
        "\n",
        "print(f\"Rolling Avg Mean Squared Error: {mse}\")\n",
        "print(f\"Rolling Avg Mean Absolute Error: {mae}\")\n",
        "print(f\"Rolling Avg R-squared: {r2}\")"
      ],
      "metadata": {
        "id": "4J8TGuKUWh2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive"
      ],
      "metadata": {
        "id": "q1nb7dK6XADk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "historical['Naive_Pred'] = historical['Return'].shift(1)"
      ],
      "metadata": {
        "id": "KooqhanNW_oy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "naive_pred = historical['Naive_Pred'].dropna()\n",
        "aligned = true_vals.loc[naive_pred.index]\n",
        "\n",
        "mse = mean_squared_error(aligned, naive_pred)\n",
        "mae = mean_absolute_error(aligned, naive_pred)\n",
        "r2 = r2_score(aligned, naive_pred)\n",
        "\n",
        "print(f\"Naive Mean Squared Error: {mse}\")\n",
        "print(f\"Naive Mean Absolute Error: {mae}\")\n",
        "print(f\"Naive R-squared: {r2}\")"
      ],
      "metadata": {
        "id": "snELC1utXM4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model with cross validation"
      ],
      "metadata": {
        "id": "vScxmzVqigfZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RandomForest"
      ],
      "metadata": {
        "id": "iVRCgBfbX2gD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "model = RandomForestRegressor(random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 300],\n",
        "    'max_depth': [5, 10],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "\n",
        "scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=model,\n",
        "    param_grid=param_grid,\n",
        "    cv=tscv,\n",
        "    scoring=scorer,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Best Score:\", best_score)"
      ],
      "metadata": {
        "id": "v7Wq_AevUMNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM"
      ],
      "metadata": {
        "id": "bFkbnZltX4Sh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.values\n",
        "y = y.values\n",
        "\n",
        "def create_sequences(X, y, time_steps=10):\n",
        "  Xs, ys = [], []\n",
        "  for i in range(len(X) - time_steps):\n",
        "    Xs.append(X[i:(i + time_steps)])\n",
        "    ys.append(y[i + time_steps])\n",
        "  return np.array(Xs), np.array(ys)\n",
        "\n",
        "X_seq, y_seq = create_sequences(X, y, time_steps=10)"
      ],
      "metadata": {
        "id": "gZ3oGzMtX5de"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lstm_model(input_shape):\n",
        "  model = tf.keras.Sequential()\n",
        "\n",
        "  model.add(layers.LSTM(64, activation=None, input_shape=input_shape, dropout=0.2, return_sequences=False))\n",
        "  model.add(layers.Dense(1))\n",
        "  model.compile(optimizer='adam', loss='mse')\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "gjZGvX11Y49p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for train_idx, val_idx in tscv.split(X_seq):\n",
        "  X_train, X_val = X_seq[train_idx], X_seq[val_idx]\n",
        "  y_train, y_val = y_seq[train_idx], y_seq[val_idx]\n",
        "\n",
        "  model = lstm_model(X_train.shape[1:])\n",
        "  model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32)"
      ],
      "metadata": {
        "id": "4pRlnvtgaD7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# finBERT"
      ],
      "metadata": {
        "id": "lj6YaBTjX7GU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# finBERT model\n",
        "tokenizer = BertTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
        "model = BertForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
        "\n",
        "finbert = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "headline = news[9]['title']\n",
        "res = finbert(headline)\n",
        "print(res)"
      ],
      "metadata": {
        "id": "WdYhudgRo2cN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in news:\n",
        "  headline = i['title']\n",
        "  res = finbert(headline)\n",
        "  print(headline, res)"
      ],
      "metadata": {
        "id": "xNAFNaawq3_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# graphing % change\n",
        "historical = historical.reset_index()\n",
        "X = pd.to_datetime(historical['Date'])\n",
        "y = historical['Change']\n",
        "\n",
        "plt.plot(X, y)\n",
        "plt.title('S&P 500')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Interday Change (%)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "5sdGNwVxI4e_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finnhub API"
      ],
      "metadata": {
        "id": "NZ02JuBmUBgi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# finnhub news api. allows for historical search\n",
        "\n",
        "finnhub_client = finnhub.Client(api_key=finhubkey)\n",
        "\n",
        "news = finnhub_client.company_news('SPY', _from=\"2025-04-01\", to=\"2025-04-01\")\n",
        "\n",
        "# for i in news:\n",
        "#   print(i['headline'])\n",
        "for i in news:\n",
        "  sentiment = finbert(i['summary'])\n",
        "  if sentiment[0]['label'] == 'neutral':\n",
        "    continue\n",
        "  print(i['summary'], sentiment)"
      ],
      "metadata": {
        "id": "p9q8Dz_-HbNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yzU8Rdy_cwzN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}